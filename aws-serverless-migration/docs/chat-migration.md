# Chat åŠŸèƒ½è¿ç§»æŒ‡å—

## ğŸ”„ ä» Express åˆ° Serverless çš„ Chat åŠŸèƒ½è¿ç§»

### åŸå§‹ Express æ¶æ„

```javascript
// Express ä¸­çš„ chat è·¯ç”±
router.post('/chat', authenticationToken, upload.single('image'), chat);

// æ§åˆ¶å™¨å¤„ç†
export const chat = async (req: Request, res: Response) => {
  const { message, model, sessionId } = req.body;
  const userId = req.user?.id;
  const imageBase64 = req.file
    ? fs.readFileSync(req.file.path, 'base64')
    : null;

  // æ ¹æ®æ¨¡å‹è°ƒç”¨ä¸åŒæœåŠ¡
  let modelResponse;
  if (model.includes('openai')) {
    modelResponse = await chatService(message, userId, sessionId, imageBase64);
  } else if (model.includes('gemini')) {
    modelResponse = await geminiChatService(
      message,
      userId,
      sessionId,
      imageBase64,
    );
  }

  res.json({
    response: modelResponse.result,
    sessionId: modelResponse.sessionId,
  });
};
```

### Serverless æ¶æ„

```yaml
# serverless.yml
functions:
  chatMessage:
    handler: src/handlers/chat.handleMessage
    events:
      - http:
          path: /api/chat/message
          method: post
          cors: true
    timeout: 30
    memorySize: 512
```

```javascript
// Lambda å¤„ç†å™¨
export const handleMessage = async (event: APIGatewayProxyEvent) => {
  const { message, model, sessionId, imageBase64 } = JSON.parse(
    event.body || '{}',
  );
  const userId = event.requestContext?.authorizer?.userId || 'anonymous';

  // æ ¹æ®æ¨¡å‹è°ƒç”¨æœåŠ¡
  let modelResponse;
  switch (model.toLowerCase()) {
    case 'openai':
      modelResponse = await openaiChatService(
        message,
        userId,
        sessionId,
        imageBase64,
      );
      break;
    case 'gemini':
      modelResponse = await geminiChatService(
        message,
        userId,
        sessionId,
        imageBase64,
      );
      break;
    case 'grok':
      modelResponse = await grokChatService(
        message,
        userId,
        sessionId,
        imageBase64,
      );
      break;
  }

  return successResponse({
    response: modelResponse.result,
    sessionId: modelResponse.sessionId,
    model: model,
  });
};
```

## ğŸš€ å·²å®ç°çš„åŠŸèƒ½

### 1. å¤šæ¨¡å‹æ”¯æŒ

- **OpenAI GPT-4**: æ”¯æŒæ–‡æœ¬å’Œå›¾ç‰‡è¾“å…¥
- **Google Gemini**: æ”¯æŒæ–‡æœ¬å’Œå›¾ç‰‡è¾“å…¥
- **Grok (xAI)**: ä¸»è¦æ”¯æŒæ–‡æœ¬è¾“å…¥

### 2. API ç«¯ç‚¹

#### å‘é€æ¶ˆæ¯

```http
POST /api/chat/message
Content-Type: application/json

{
  "message": "Hello, can you help me?",
  "model": "openai",
  "sessionId": "optional-session-id",
  "imageBase64": "optional-base64-image"
}
```

#### è·å–èŠå¤©å†å² (éœ€è¦è®¤è¯)

```http
GET /api/chat/history/{sessionId}
Authorization: Bearer <jwt-token>
```

#### æ¸…é™¤èŠå¤©å†å² (éœ€è¦è®¤è¯)

```http
DELETE /api/chat/history/{sessionId}
Authorization: Bearer <jwt-token>
```

### 3. æ”¯æŒçš„æ¨¡å‹å‚æ•°

| æ¨¡å‹   | å‚æ•°å€¼   | æ”¯æŒå›¾ç‰‡ | API Key ç¯å¢ƒå˜é‡                |
| ------ | -------- | -------- | ------------------------------- |
| OpenAI | `openai` | âœ…       | `OPENAI_API_KEY`                |
| Gemini | `gemini` | âœ…       | `GEMINI_API_KEY`                |
| Grok   | `grok`   | âŒ       | `GROK_API_KEY` æˆ– `XAI_API_KEY` |

## ğŸ”§ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡

```bash
# .env æ–‡ä»¶
OPENAI_API_KEY=sk-your-openai-api-key
GEMINI_API_KEY=your-gemini-api-key
GROK_API_KEY=your-grok-api-key
XAI_API_KEY=your-xai-api-key
```

### Lambda é…ç½®

- **Timeout**: 30 ç§’ (AI å“åº”å¯èƒ½è¾ƒæ…¢)
- **Memory**: 512MB (å¤„ç†å›¾ç‰‡å’Œ AI æ¨¡å‹)
- **Runtime**: Node.js 18.x

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### å‰ç«¯é›†æˆ

```javascript
class ChatService {
  constructor(apiBase, authToken = null) {
    this.apiBase = apiBase;
    this.authToken = authToken;
  }

  async sendMessage(
    message,
    model = 'openai',
    sessionId = null,
    imageBase64 = null,
  ) {
    const response = await fetch(`${this.apiBase}/api/chat/message`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...(this.authToken && { Authorization: `Bearer ${this.authToken}` }),
      },
      body: JSON.stringify({
        message,
        model,
        sessionId,
        imageBase64,
      }),
    });

    if (!response.ok) {
      throw new Error(`Chat failed: ${response.status}`);
    }

    return await response.json();
  }

  async getChatHistory(sessionId) {
    const response = await fetch(
      `${this.apiBase}/api/chat/history/${sessionId}`,
      {
        headers: {
          Authorization: `Bearer ${this.authToken}`,
        },
      },
    );

    return await response.json();
  }
}

// ä½¿ç”¨ç¤ºä¾‹
const chatService = new ChatService('https://your-api.amazonaws.com/dev');

// å‘é€æ–‡æœ¬æ¶ˆæ¯
const response = await chatService.sendMessage(
  'What products do you recommend?',
  'openai',
);

console.log('AI Response:', response.response);
console.log('Session ID:', response.sessionId);

// å‘é€å¸¦å›¾ç‰‡çš„æ¶ˆæ¯
const imageResponse = await chatService.sendMessage(
  'What do you see in this image?',
  'gemini',
  response.sessionId,
  base64ImageData,
);
```

### React ç»„ä»¶ç¤ºä¾‹

```jsx
import React, { useState } from 'react';

const ChatComponent = () => {
  const [messages, setMessages] = useState([]);
  const [input, setInput] = useState('');
  const [sessionId, setSessionId] = useState(null);
  const [model, setModel] = useState('openai');

  const sendMessage = async () => {
    if (!input.trim()) return;

    const userMessage = { role: 'user', content: input };
    setMessages((prev) => [...prev, userMessage]);

    try {
      const response = await fetch('/api/chat/message', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          message: input,
          model: model,
          sessionId: sessionId,
        }),
      });

      const data = await response.json();

      if (response.ok) {
        const aiMessage = { role: 'assistant', content: data.response };
        setMessages((prev) => [...prev, aiMessage]);
        setSessionId(data.sessionId);
      } else {
        console.error('Chat error:', data.error);
      }
    } catch (error) {
      console.error('Network error:', error);
    }

    setInput('');
  };

  return (
    <div className="chat-container">
      <div className="model-selector">
        <select value={model} onChange={(e) => setModel(e.target.value)}>
          <option value="openai">OpenAI GPT-4</option>
          <option value="gemini">Google Gemini</option>
          <option value="grok">Grok</option>
        </select>
      </div>

      <div className="messages">
        {messages.map((msg, index) => (
          <div key={index} className={`message ${msg.role}`}>
            <strong>{msg.role}:</strong> {msg.content}
          </div>
        ))}
      </div>

      <div className="input-area">
        <input
          type="text"
          value={input}
          onChange={(e) => setInput(e.target.value)}
          onKeyPress={(e) => e.key === 'Enter' && sendMessage()}
          placeholder="Type your message..."
        />
        <button onClick={sendMessage}>Send</button>
      </div>
    </div>
  );
};

export default ChatComponent;
```

## ğŸ” æµ‹è¯•å’Œè°ƒè¯•

### æœ¬åœ°æµ‹è¯•

```bash
# å¯åŠ¨æœ¬åœ°æœåŠ¡å™¨
npm run dev

# æµ‹è¯•chatåŠŸèƒ½
npm run test:api:dev

# æ‰‹åŠ¨æµ‹è¯•
curl -X POST http://localhost:3000/api/chat/message \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Hello, how can you help me?",
    "model": "openai"
  }'
```

### ç”Ÿäº§ç¯å¢ƒæµ‹è¯•

```bash
# éƒ¨ç½²åˆ°AWS
npm run deploy

# æµ‹è¯•çº¿ä¸ŠAPI
API_BASE=https://your-api-id.execute-api.us-east-1.amazonaws.com/dev npm run test:api
```

## ğŸš¨ æ³¨æ„äº‹é¡¹

### 1. API å¯†é’¥å®‰å…¨

- æ‰€æœ‰ API å¯†é’¥éƒ½é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®
- ä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç  API å¯†é’¥
- ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ AWS Secrets Manager

### 2. æˆæœ¬æ§åˆ¶

- AI API è°ƒç”¨ä¼šäº§ç”Ÿè´¹ç”¨
- è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
- è€ƒè™‘å®ç°è¯·æ±‚é¢‘ç‡é™åˆ¶

### 3. é”™è¯¯å¤„ç†

- ç½‘ç»œè¶…æ—¶å¤„ç†
- API é…é¢é™åˆ¶å¤„ç†
- æ¨¡å‹ä¸å¯ç”¨æ—¶çš„é™çº§ç­–ç•¥

### 4. æ€§èƒ½ä¼˜åŒ–

- åˆç†è®¾ç½® Lambda å†…å­˜å¤§å°
- è€ƒè™‘è¿æ¥å¤ç”¨
- å®ç°å“åº”ç¼“å­˜æœºåˆ¶

## ğŸ“Š ä¸ Express ç‰ˆæœ¬å¯¹æ¯”

| ç‰¹æ€§         | Express        | Serverless       |
| ------------ | -------------- | ---------------- |
| **éƒ¨ç½²**     | å•ä¸ªæœåŠ¡å™¨     | ç‹¬ç«‹ Lambda å‡½æ•° |
| **æ‰©å±•**     | æ‰‹åŠ¨æ‰©å±•       | è‡ªåŠ¨æ‰©å±•         |
| **æˆæœ¬**     | å›ºå®šæœåŠ¡å™¨æˆæœ¬ | æŒ‰è¯·æ±‚ä»˜è´¹       |
| **å†·å¯åŠ¨**   | æ—              | é¦–æ¬¡è°ƒç”¨æœ‰å»¶è¿Ÿ   |
| **æ–‡ä»¶ä¸Šä¼ ** | Multer ä¸­é—´ä»¶  | Base64 ç¼–ç       |
| **ä¼šè¯ç®¡ç†** | å†…å­˜/æ•°æ®åº“    | æ•°æ®åº“           |
| **é”™è¯¯å¤„ç†** | å…¨å±€ä¸­é—´ä»¶     | å‡½æ•°çº§å¤„ç†       |

## âœ… è¿ç§»å®Œæˆæ£€æŸ¥æ¸…å•

- [x] Chat å¤„ç†å™¨å®ç°
- [x] å¤šæ¨¡å‹æœåŠ¡æ”¯æŒ (OpenAI, Gemini, Grok)
- [x] å›¾ç‰‡è¾“å…¥æ”¯æŒ
- [x] ä¼šè¯ç®¡ç†
- [x] é”™è¯¯å¤„ç†
- [x] CORS é…ç½®
- [x] ç¯å¢ƒå˜é‡é…ç½®
- [x] æµ‹è¯•è„šæœ¬
- [ ] æ•°æ®åº“é›†æˆ (èŠå¤©å†å²å­˜å‚¨)
- [ ] è®¤è¯é›†æˆ
- [ ] ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
- [ ] ç›‘æ§å’Œæ—¥å¿—

ç°åœ¨ä½ çš„ Serverless åº”ç”¨å·²ç»å®Œå…¨æ”¯æŒ AI èŠå¤©åŠŸèƒ½äº†ï¼ğŸ‰
